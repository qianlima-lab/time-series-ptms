This is the time-series forecasting training code for our paper *"A Survey on Time-Series Pre-Trained Models"*

## Baselines

|  ID  |                            Method                            | Year |   Press   |                         Source Code                          |
| :--: | :----------------------------------------------------------: | :--: | :-------: | :----------------------------------------------------------: |
|  1   |  [LogTrans](https://proceedings.neurips.cc/paper/2019/file/6775a0635c302542da2c32aa19d86be0-Paper.pdf)  | 2019 |    NIPS    |     [github_link](https://github.com/mlpotter/Transformer_Time_Series)      |
|  2   | [TCN](https://arxiv.org/abs/1803.01271)  | 2018 |    arXiv    |     [github_link](https://github.com/locuslab/TCN)      |
|  3   | [Informer](https://ojs.aaai.org/index.php/AAAI/article/view/17325/17132) | 2020 | AAAI | [github_link](https://github.com/zhouhaoyi/Informer2020) |
|  4   | [Autoformer](https://proceedings.neurips.cc/paper/2021/hash/bcc0d400288793e8bdcd7c19a8ac0c2b-Abstract.html)  | 2021 |    NIPS    |     [github_link](https://github.com/thuml/autoformer)      |
|  5   | [TS2Vec](https://www.aaai.org/AAAI22Papers/AAAI-8809.YueZ.pdf) | 2022 |   AAAI    |      [github_link](https://github.com/yuezhihan/ts2vec)      |
|  6   |            [CoST](https://openreview.net/forum?id=PilZY3omXV2)            | 2022 |   ICLR    | [github_link](https://github.com/salesforce/CoST) |
|  7   |            [TimesNet](https://arxiv.org/abs/2210.02186)            | 2023 |   ICLR    | [github_link](https://github.com/thuml/TimesNet) |
|  8   |            [PatchTST](https://arxiv.org/abs/2211.14730)            | 2023 |   ICLR    | [github_link](https://github.com/yuqinie98/PatchTST) |
|  9   |            [DLinear](https://arxiv.org/pdf/2205.13504)            | 2023 |   ICLR    | [github_link](https://github.com/vivva/DLinear) |
|  10   |            [GPT4TS](https://arxiv.org/abs/2302.11939)            | 2023 |   NeurIPS    | [github_link](https://github.com/DAMO-DI-ML/NeurIPS2023-One-Fits-All) |
|  11   |            [TEMPO](https://openreview.net/forum?id=YH5w12OUuU)            | 2024 |   ICLR    | [github_link](https://github.com/DC-research/TEMPO) |
|  12   |            [iTransformer](https://openreview.net/forum?id=JePfAI8fah)            | 2024 |   ICLR    | [github_link](hhttps://github.com/thuml/iTransformer) |

For details, please refer to [ts_forecasting_methods/Other_baselines/README]()
